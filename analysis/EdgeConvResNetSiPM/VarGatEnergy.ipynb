{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 21:12:16.311168: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-21 21:12:16.320010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-21 21:12:16.328749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-21 21:12:16.331535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-21 21:12:16.339291: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-21 21:12:16.712136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spektral.data import Dataset, Graph\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "os.chdir(\"/home/philippe/Master/github/SiFiCC-NN/datasets/OptimisedGeometry_CodedMaskHIT_Spot1_2e10_protons_simv5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load data from files\n",
    "def load_data():\n",
    "    adjacency_list = np.load(\"A.npy\")  \n",
    "    node_attributes = np.load(\"node_attributes.npy\")  \n",
    "    node_indicator = np.load(\"node_indicator.npy\")\n",
    "    edge_attributes = np.load(\"edge_attributes.npy\")  \n",
    "    edge_indicator = np.load(\"edge_indicator.npy\")\n",
    "    return adjacency_list, node_attributes, node_indicator, edge_attributes, edge_indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit\n",
    "def create_adjacency_matrix(edges, num_nodes):\n",
    "    adj_matrix = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
    "    for i in range(edges.shape[0]):\n",
    "        src, dst = edges[i]\n",
    "        adj_matrix[src, dst] = 1\n",
    "    return adj_matrix\n",
    "\n",
    "\n",
    "def find_graph_start_indices(indicator_array):\n",
    "    # Find indices where the graph index changes (i.e., where a new graph begins)\n",
    "    graph_start_indices = np.where(np.diff(indicator_array, prepend=-1) != 0)[0]\n",
    "    return graph_start_indices\n",
    "\n",
    "class MyGraphDataset(Dataset):\n",
    "    def __init__(self, adjacency_list, node_attributes, node_indicator, edge_attributes, edge_indicator, **kwargs):\n",
    "        self.adjacency_list = adjacency_list\n",
    "        self.node_attributes = node_attributes\n",
    "        self.node_indicator = node_indicator\n",
    "        self.edge_attributes = edge_attributes\n",
    "        self.edge_indicator = edge_indicator\n",
    "        \n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        graphs = []\n",
    "        # Compute start indices for nodes and edges\n",
    "        self.node_start_indices = find_graph_start_indices(self.node_indicator)\n",
    "        self.edge_start_indices = find_graph_start_indices(self.edge_indicator)\n",
    "        \n",
    "        self.num_graphs = len(self.node_start_indices)  # Number of graphs\n",
    "\n",
    "        # Iterate over each graph index\n",
    "        for i in tqdm(range(self.num_graphs), desc=\"Populating Graphs\"):\n",
    "            # Determine the start and end indices for the current graph\n",
    "            node_start = self.node_start_indices[i]\n",
    "            node_end = self.node_start_indices[i + 1] if i + 1 < self.num_graphs else len(self.node_indicator)\n",
    "            \n",
    "            edge_start = self.edge_start_indices[i]\n",
    "            edge_end = self.edge_start_indices[i + 1] if i + 1 < self.num_graphs else len(self.edge_indicator)\n",
    "\n",
    "            # Extract node and edge attributes for the current graph\n",
    "            x = self.node_attributes[node_start:node_end]\n",
    "            e = self.edge_attributes[edge_start:edge_end]\n",
    "\n",
    "            # Extract edges for the current graph\n",
    "            edges = self.adjacency_list[edge_start:edge_end]\n",
    "\n",
    "            # Determine the number of nodes in the current graph\n",
    "            num_nodes = node_end - node_start\n",
    "\n",
    "            # Create adjacency matrix using Numba-optimized function\n",
    "            adj_matrix = create_adjacency_matrix(edges, num_nodes)\n",
    "\n",
    "            # Create Graph object and append to the list\n",
    "            graph = Graph(x=x, a=adj_matrix, e=e)\n",
    "            graphs.append(graph)\n",
    "\n",
    "        return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "adjacency_list, node_attributes, node_indicator, edge_attributes, edge_indicator = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating Graphs: 100%|██████████| 993783/993783 [00:03<00:00, 293883.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = MyGraphDataset(adjacency_list, node_attributes, node_indicator, edge_attributes, edge_indicator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class GATLayer(layers.Layer):\n",
    "    def __init__(self, num_heads, num_out_features, **kwargs):\n",
    "        super(GATLayer, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.num_out_features = num_out_features\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_nodes = input_shape[0][1]\n",
    "        num_in_features = input_shape[0][-1]\n",
    "        self.attn_weights = self.add_weight(shape=(num_in_features, self.num_out_features),\n",
    "                                            initializer='glorot_uniform', name='attn_weights')\n",
    "        self.attn_bias = self.add_weight(shape=(self.num_out_features,), initializer='zeros', name='attn_bias')\n",
    "        super(GATLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj = inputs\n",
    "        features_transformed = tf.matmul(features, self.attn_weights)\n",
    "        attn_scores = tf.matmul(features_transformed, features_transformed, transpose_b=True)\n",
    "        attn_scores += self.attn_bias\n",
    "        attn_scores = tf.nn.softmax(attn_scores, axis=-1)\n",
    "        aggregated_features = tf.matmul(attn_scores, features_transformed)\n",
    "        return aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gat_model(num_node_features, num_edge_features, num_out_features):\n",
    "    features_input = layers.Input(shape=(None, num_node_features), name='node_features')\n",
    "    adj_input = layers.Input(shape=(None, None), name='adj_matrix')\n",
    "\n",
    "    x = GATLayer(num_heads=1, num_out_features=224)([features_input, adj_input])\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dense(num_out_features, activation='relu')(x)\n",
    "    edge_features_output = layers.Dense(num_edge_features, activation='linear')(x)\n",
    "\n",
    "    model = models.Model(inputs=[features_input, adj_input], outputs=edge_features_output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preparing the data for training\n",
    "def prepare_data(graphs):\n",
    "    node_features = []\n",
    "    adj_matrices = []\n",
    "    edge_features = []\n",
    "\n",
    "    for graph in tqdm(graphs):\n",
    "        node_features.append(graph.x)\n",
    "        adj_matrices.append(graph.a)\n",
    "        edge_features.append(graph.e)\n",
    "\n",
    "    return np.array(node_features, dtype=object), np.array(adj_matrices, dtype=object), np.array(edge_features, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993783/993783 [00:00<00:00, 1806794.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract node features, adjacency matrices, and edge features\n",
    "node_features, adj_matrices, edge_features = prepare_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, A_train, A_test, y_train, y_test = train_test_split(\n",
    "    node_features, adj_matrices, edge_features, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the GAT model\n",
    "num_node_features = node_features[0].shape[1]\n",
    "num_edge_features = edge_features[0].shape[1]\n",
    "num_out_features = num_edge_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724267592.599095    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.631765    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.637290    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.641780    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.651069    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.655106    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.767442    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.768582    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724267592.769564    2669 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-21 21:13:12.770544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5476 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = build_gat_model(num_node_features, num_edge_features, num_out_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Master/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/Master/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit([X_train, A_train], y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
